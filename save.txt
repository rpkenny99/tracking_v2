import cv2 as cv2
import numpy as np
from cv2 import aruco

markerDict = aruco.getPredefinedDictionary(aruco.DICT_6X6_50)
paramMarkers = aruco.DetectorParameters()
calib_data_path = "calib_data/MultiMatrix.npz"
calib_data = np.load(calib_data_path)

cam_mat = calib_data["camMatrix"]
dist_coef = calib_data["distCoef"]
r_vectors = calib_data["rVector"]
t_vectors = calib_data["tVector"]

MARKER_SIZE = 10.87

def ResizeInputTestPhoto(frame):
    # Display
    scale_percent = 50  # Resize to 20% of the original size (adjust as needed)
    width = int(frame.shape[1] * scale_percent / 100)
    height = int(frame.shape[0] * scale_percent / 100)
    return cv2.resize(frame, (width, height), interpolation=cv2.INTER_AREA)

def DisplayFrame(frame, thresh_frame=None):
    cv2.imshow("preview", frame)
    if thresh_frame is not None:
        cv2.imshow("preview_2", thresh_frame)

def ProcessFrame(frame):
    # Create a copy of the frame to work with
    frame_copy = frame.copy()

    # Convert the frame to grayscale
    grayFrame = cv2.cvtColor(frame_copy, cv2.COLOR_BGR2GRAY)

    # Apply thresholding to create a binary image
    # _, threshold_image = cv2.threshold(grayFrame, 80, 255, cv2.THRESH_BINARY)
    # threshold_image = cv2.adaptiveThreshold(grayFrame, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 15, 5)
    threshold_image = grayFrame

    # Detect ArUco markers in the thresholded image
    markerCorners, markerIds, rejects = aruco.detectMarkers(
        threshold_image, markerDict, parameters=paramMarkers
    )

    # Only draw on the frame (not the thresholded image)
    if markerIds is not None and markerCorners is not None:
        total_markers = range(0, markerIds.size)
        for id, corners, i in zip(markerIds, markerCorners, total_markers):
            # Draw marker boundary on the frame
            cv2.polylines(frame_copy, [corners.astype(np.int32)], True, (0, 255, 255), 4, cv2.LINE_AA)
            print(f"{id=}, {corners[0]=}")
            corners = corners.reshape(4, 2)
            corners = corners.astype(np.float64)
            top_right = corners[0].ravel()

            print(f"{corners=}")

            rVec, tVec, _ = aruco.estimatePoseSingleMarkers(markerCorners, MARKER_SIZE, cam_mat, dist_coef)

            
            # Draw the pose of the marker on the frame
            # point = cv2.drawFrameAxes(frame_copy, cam_mat, dist_coef, rVec[i], tVec[i], 4, 4)

            
            # Define termination criteria (e.g., use epsilon and max iterations)
            term_criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 100, 0.001)
            # Reshape the corners into the required format
            # Convert the tuple to a NumPy array first
            print(f"{rVec=}, {tVec=}")
            current_rVec = np.asarray(rVec[0][i], dtype=np.float64)
            current_tVec = np.asarray(tVec[0][i], dtype=np.float64)
            marker_corners_3D, _ = RotateMarkersCorners(current_rVec, MARKER_SIZE, current_tVec)
            
            refined_rVec, refined_tVec = cv2.solvePnPRefineLM(marker_corners_3D,
                                                              corners,
                                                              cam_mat,
                                                              dist_coef,
                                                              current_rVec,
                                                              current_tVec,
                                                              term_criteria)

            print(f"{marker_corners_3D=}")
            # Draw refined axes (after pose refinement)
            cv2.drawFrameAxes(frame_copy, cam_mat, dist_coef, refined_rVec, refined_tVec, 4, 4)

            print(f"{tuple(top_right)=}")
            # Draw the marker ID on the frame
            cv2.putText(frame_copy, f"{id=}", tuple(top_right), cv2.FONT_HERSHEY_PLAIN, 1.3, (0, 255, 0), 2, cv2.LINE_AA)

    # Return the processed frame and the thresholded image separately
    return frame_copy, threshold_image            

def RefinePose(markerCorners, cameraMatrix, distCoeffs):
    """
    Refine the pose of the dodecahedron using solvePnP.
    
    :param markerCorners: Detected marker corners (4 corners of the marker)
    :param cameraMatrix: Camera matrix (intrinsic parameters)
    :param distCoeffs: Distortion coefficients of the camera
    :return: Refined rotation and translation vectors (rVec, tVec)
    """
    # Define the 3D coordinates of the corners of the marker in the marker's coordinate system
    # Assuming the marker is flat on the Z=0 plane
    markerObjectPoints = np.array([
        [-MARKER_SIZE/2, MARKER_SIZE/2, 0],  # top-left corner
        [MARKER_SIZE/2, MARKER_SIZE/2, 0],   # top-right corner
        [MARKER_SIZE/2, -MARKER_SIZE/2, 0],  # bottom-right corner
        [-MARKER_SIZE/2, -MARKER_SIZE/2, 0]  # bottom-left corner
    ], dtype=np.float32)

    # Reshape the corners into the required format
    markerCorners = markerCorners.reshape((4, 2))  # 2D points in the image

    # Use solvePnP to refine the rotation and translation vectors
    success, rVec, tVec = cv2.solvePnP(markerObjectPoints, markerCorners, cameraMatrix, distCoeffs)

    if not success:
        print("Pose estimation failed")
        return None, None

    return rVec, tVec

def RotateMarkersCorners(rvec, markersize, tvec = None):

    mhalf = markersize / 2.0
    # convert rot vector to rot matrix both do: markerworld -> cam-world
    mrv, jacobian = cv2.Rodrigues(rvec)

    #in markerworld the corners are all in the xy-plane so z is zero at first
    X = mhalf * mrv[:,0] #rotate the x = mhalf
    Y = mhalf * mrv[:,1] #rotate the y = mhalf
    minusX = X * (-1)
    minusY = Y * (-1)

    # calculate 4 corners of the marker in camworld. corners are enumerated clockwise
    markercorners = []
    markercorners.append(np.add(minusX, Y)) #was upper left in markerworld
    markercorners.append(np.add(X, Y)) #was upper right in markerworld
    markercorners.append(np.add( X, minusY)) #was lower right in markerworld
    markercorners.append(np.add(minusX, minusY)) #was lower left in markerworld
    # if tvec given, move all by tvec
    if tvec is not None:
        C = tvec #center of marker in camworld
        for i, mc in enumerate(markercorners):
            markercorners[i] = np.add(C,mc) #add tvec to each corner
    #print('Vec X, Y, C, dot(X,Y)', X,Y,C, np.dot(X,Y)) # just for debug
    markercorners = np.array(markercorners,dtype=np.float32) # type needed when used as input to cv2
    return markercorners, mrv

def RunTestImageDetection():
    frame = cv2.imread('WIN_20241014_22_28_04_Pro.jpg')
    cv2.namedWindow('preview', cv2.WINDOW_NORMAL)
    cv2.namedWindow('preview_2', cv2.WINDOW_NORMAL)

    rval = True
    while rval:
        # resized_frame = ResizeInputTestPhoto(frame)
        # rval, frame = vc.read()
        post_process_frame, thresh_frame = ProcessFrame(frame)

        key = cv2.waitKey(20)
        if key == 27: # exit on ESC
            break

        DisplayFrame(post_process_frame, thresh_frame)

def ResizeFrameToAspectRatio(frame, width=640, height=480):
    # Resize the frame to the specified width and height while maintaining aspect ratio
    return cv2.resize(frame, (width, height), interpolation=cv2.INTER_AREA)

def InitializeBrio(vc):
    # Set the frame rate to 30 FPS
    vc.set(cv2.CAP_PROP_FPS, 60)

    # Set the camera resolution to 4K (3840x2160)
    # vc.set(cv2.CAP_PROP_FRAME_WIDTH, 4096)
    # vc.set(cv2.CAP_PROP_FRAME_HEIGHT, 2160)

    # vc.set(cv2.CAP_PROP_CONTRAST, 100)  # Try setting a high contrast level

def RunVideoCaptureDetection(vidCapturePath=None):
    print("Trying to open video capture device")
    if vidCapturePath is None:
        vc = cv2.VideoCapture(0)
    else:
        vc = cv2.VideoCapture(vidCapturePath)

    if vc.isOpened(): # try to get the first frame
        print("Video capture device opened successfully!")
        print("Initializing video capture device...")
        InitializeBrio(vc)
        print("Initialization completed!")
        print("Reading first frame...")
        rval, frame = vc.read()
        print("First frame read successfully!")
    else:
        rval = False

    

    while rval:
        post_process_frame, threshold_image = ProcessFrame(frame)
        rval, frame = vc.read()

        key = cv2.waitKey(20)
        if key == 27: # exit on ESC
            break

        DisplayFrame(post_process_frame, thresh_frame=threshold_image)
    vc.release()

RunTestImageDetection()
# RunVideoCaptureDetection()
# RunVideoCaptureDetection("ArucoTestVideo_2.mp4")

cv2.destroyWindow("preview")